---
title: "Stats Final Project"
author: "Lenka and Nina"
date: "2022-12-02"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(fastDummies)
library(glmnet)
library(pscl)
```

# Recidivism Project

## Loading Data

```{r cars}
data = read.csv("NIJ_s_Recidivism_Challenge_Full_Dataset.csv")
```

## Pre-processing 

data viz

```{r}
head(data,10)
```
```{r}
### Investigate missing values
data_cleaned <- data %>%
  mutate_all(~na_if(., ''))

# Column-wise
colSums(is.na(data_cleaned)) 

# Missing vals for female vs male
colSums(is.na(data_cleaned %>% filter(Gender == "M"))) 
#nrow(data_cleaned %>% filter(Gender == "F"))

# Row-wise
summary((rowSums(is.na(data_cleaned))))

# Investigate missing drug test data
#missing_drug_tests <- data_cleaned %>% filter(is.na(DrugTests_THC_Positive) | is.na(DrugTests_Meth_Positive))
#colSums(is.na(missing_drug_tests))

# Investigate missing Jobs data 
#missing_jobs <- data_cleaned %>% filter(is.na(Jobs_Per_Year))
#colSums(is.na(missing_jobs))

# For now just drop NAs
#data_cleaned <- data_cleaned %>%
#  na.omit() # removes almost half of our observations but data set still very large (note that this removes all entries for females)
```

```{r}
### Resolve missing data 

# Categorical vars
data_cleaned <- data_cleaned %>%
  mutate(Gang_Affiliated = ifelse(Gender == "F", "false", Gang_Affiliated),
         Supervision_Risk_Score_First = ifelse(is.na(Supervision_Risk_Score_First), "missing",   Supervision_Risk_Score_First),
         Supervision_Level_First = ifelse(is.na(Supervision_Level_First), "missing", Supervision_Level_First),
         Prison_Offense = ifelse(is.na(Prison_Offense), "missing", Prison_Offense))

# Remove 'DrugTest' vars (significant proportion is missing)
data_cleaned <- data_cleaned %>%
  select(-c(DrugTests_THC_Positive, DrugTests_Cocaine_Positive, DrugTests_Meth_Positive, DrugTests_Other_Positive, Avg_Days_per_DrugTest))

# Replace missing jobs data with values 0
data_cleaned <- data_cleaned %>%
  mutate(Percent_Days_Employed = ifelse(is.na(Percent_Days_Employed), 0, Percent_Days_Employed),
         Jobs_Per_Year = ifelse(is.na(Jobs_Per_Year), 0, Jobs_Per_Year))

colSums(is.na(data_cleaned)) 
```


```{r}
### Set up dependent var and covariate matrix
y <- data_cleaned %>%
  select(Recidivism_Within_3years) %>%
  mutate(Recidivism_Within_3years = ifelse(Recidivism_Within_3years == "true", 1, 0)) %>%
  as.matrix()

# 8423 observations correspond to a reoffence within three years
#sum(y$Recidivism_Within_3years)/length(y)

### Covariate matrix - removed supervision_risk_score as this is what we're trying to predict
X <- data_cleaned %>%
  select(-c(ID, Recidivism_Arrest_Year1, Recidivism_Arrest_Year2, Recidivism_Arrest_Year3, Training_Sample,Recidivism_Within_3years, Supervision_Risk_Score_First)) 

# dummy col 
#dummy_colnames <- X %>% select(-c(Avg_Days_per_DrugTest, DrugTests_THC_Positive,DrugTests_Cocaine_Positive, #DrugTests_Meth_Positive, DrugTests_Other_Positive, Percent_Days_Employed, Jobs_Per_Year)) %>%
#  names()
dummy_colnames <- X %>% select(-c(Percent_Days_Employed, Jobs_Per_Year)) %>%
  names()

X <- dummy_cols(X, select_columns = dummy_colnames, remove_first_dummy = TRUE, remove_selected_columns = TRUE)

X <- model.matrix(~., data = X)

```

## Fit regular logisitic model

```{r}
glm.fit <- glm(y ~.,family=binomial(link='logit'), data = as.data.frame(X[,-1]))

summary(glm.fit)

## Store results
results <- glm.fit %>% 
  tidy() 

results[,2:ncol(results)] <- round(results[,2:ncol(results)], 4) 

results <- results %>%
  mutate(exp_estimate = exp(estimate))

# Check in-sample fit
pred <- predict(glm.fit, newx = X[,-1])

assess.glmnet(pred, newy = y, family = "binomial")

# Pseudo R2
round(pR2(glm.fit),2)
```
```{r}
### Assess out-of-sample performance

#Implement 10-fold Cross validation
kfoldCV.mle <- function(y , x, K = 10, seed = 1) {
  ## Perform K-fold cross-validation for logistic regression
  ## Input
  ## - y: response
  ## - x: data.frame with predictors, intercept should not be present
  ## - K: number of folds in K-fold cross-validation
  ## - seed: random number generator seed (optional)
  ## Output
  ## - pred: cross-validated predictions for y
  ## - ssr: residual sum of squares, sum((y-pred)^2)
  if (!missing(seed)) set.seed(seed)
  subset <- rep(1:K,ceiling(nrow(x)/K))[1:nrow(x)]
  subset <- sample(subset,size=nrow(x),replace=FALSE)
  pred <- double(nrow(x))
  if (ncol(x)>0) {
    for (k in 1:K) {
      sel <- subset==k 
      fit <- glmnet(x=x[!sel,,drop=FALSE], y=y[!sel], family="binomial", lambda=0)  
      pred[sel] <- predict(fit, newx=x[sel,,drop=FALSE])
    }
  } else {
    for (k in 1:K) {
      sel <- subset==k
      pred[sel] <- mean(y[!sel],na.rm=TRUE)
    }
  }
  return(list(pred=pred))
}

cv.mle = kfoldCV.mle(y = y, x= as.matrix(X[,-1]), K = 10, seed = 1)

# 10-fold cross-validated AUC
round(assess.glmnet(cv.mle$pred, newy = y, family = "binomial")$auc, 5)
```


# LASSO
```{r}
### LASSO Model
cv_lasso <- cv.glmnet(X, y, family="binomial", n_folds = 5, type.measure = 'auc')

plot(cv_lasso)

# In-sample AUC
paste("AUC: ", round(cv_lasso$cvm[cv_lasso$index[1]], 5))

# Non-zero covariates
cv_lasso$nzero[cv_lasso$index[1]]

```