---
title: "Stats Final Project"
author: "Lenka and Nina"
date: "2022-12-02"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(fastDummies)
library(glmnet)
library(broom)
library(pscl)
library(xtable)
select <- dplyr::select
```

```{r}
#functions 
lasso.bic <- function(y,x,extended=FALSE) {
  #Select model in LASSO path with best BIC (using LASSO regression estimates)
  #Input
  # - y: vector with response variable
  # - x: design matrix
  #
  #Output: list with the following elements
  # - coef: LASSO-estimated regression coefficient with lambda set via BIC
  # - ypred: predicted y
  # - lambda.opt: optimal value of lambda
  # - lambda: data.frame with bic and number of selected variables for each value of lambda
  require(glmnet)
  fit <- glmnet(x=x,y=y,family='binomial',alpha=1)
  pred <- cbind(1,x) %*% rbind(fit$a0,fit$beta)
  n <- length(y)
  p <- colSums(fit$beta!=0) + 1
  if (!extended){
    bic <- deviance(fit) + log(n)*p 
  } else {
    bic <- deviance(fit) + log(n)*p + 2*log(choose(ncol(x),p))
  }

  sel <- which.min(bic)
  beta <- c(fit$a0[sel],fit$beta[,sel]); names(beta)[1]= 'Intercept'
  ypred <- pred[,sel]
  ans <- list(coef=beta,ypred=ypred,lambda.opt=fit$lambda[sel],lambda=data.frame(lambda=fit$lambda,bic=bic,nvars=p))
  return(ans)
}

kfoldCV.lasso <- function(y,x,K=10,seed,criterion='cv') {
## Perform K-fold cross-validation for LASSO regression estimate (lambda set either via cross-val or BIC or EBIC)
## Input
## - y: response
## - x: data.frame with predictors, intercept should not be present
## - K: number of folds in K-fold cross-validation
## - seed: random number generator seed (optional)
## - criterion: the criterion to select the penalization parameter, either cross-val or BIC or EBIC
## Output
## - pred: cross-validated predictions for y
## - ssr: residual sum of squares, sum((y-pred)^2)
  require(glmnet)
  if (!missing(seed)) set.seed(seed)
  subset <- rep(1:K,ceiling(nrow(x)/K))[1:nrow(x)]
  subset <- sample(subset,size=nrow(x),replace=FALSE)
  pred <- double(nrow(x))
  cat("Starting cross-validation")
  if (ncol(x)>0) {  #if there are some covariates
    for (k in 1:K) {
        sel <- subset==k
        if (criterion=='cv') {
            fit <- cv.glmnet(x=x[!sel,,drop=FALSE], y=y[!sel], alpha = 1, nfolds=10,family = 'binomial',type_measure='auc')
            b= as.vector(coef(fit,s='lambda.min'))
            pred[sel] <- b[1] + x[sel,,drop=FALSE] %*% as.matrix(b[-1])
         } else if (criterion=='adaptive_cv') {
            fit <- cv.glmnet(x=x[!sel,,drop=FALSE], y=y[!sel], alpha = 1, nfolds=10,family = 'binomial',type_measure='auc')
            lasso_coef <- 1/abs(matrix(coef(fit, s=fit$lambda.min)))
lasso_coef[lasso_coef== Inf] <- 999999999
adapt_fit <- cv.glmnet(x=x[!sel,,drop=FALSE], y=y[!sel], alpha = 1, nfolds=10,family = 'binomial',type_measure='auc', penalty.factor=lasso_coef[2:length(lasso_coef)])
            b= as.vector(coef(adapt_fit,s='lambda.min'))
            pred[sel] <- b[1] + x[sel,,drop=FALSE] %*% as.matrix(b[-1])
        } else if (criterion=='bic'){
            fit <- lasso.bic(y=y[!sel],x=x[!sel,,drop=FALSE])
            pred[sel] <- fit$coef[1] + x[sel,,drop=FALSE] %*% matrix(fit$coef[-1],ncol=1)
        } else if (criterion=='ebic'){
            fit <- lasso.bic(y=y[!sel],x=x[!sel,,drop=FALSE],extended = TRUE)
            pred[sel] <- fit$coef[1] + x[sel,,drop=FALSE] %*% matrix(fit$coef[-1],ncol=1) 
        } else { stop("method.lambda not implemented") }
        cat(".")
    }
  } else { #if there are no covariates, just use the intercept
    for (k in 1:K) {
      sel <- subset==k
      pred[sel] <- mean(y[!sel],na.rm=TRUE)
    }
  }
  cat("\n")
  return(list(pred=pred,ssr=sum((pred-y)^2,na.rm=TRUE)))
  }
}
```

# Recidivism Project

## Loading Data

```{r cars}
data = read.csv("NIJ_s_Recidivism_Challenge_Full_Dataset.csv")
```

## Pre-processing

data viz

```{r}
head(data,10)
```

```{r}
### Investigate missing values
data_cleaned <- data %>%
  mutate_all(~na_if(., ''))

# Column-wise
colSums(is.na(data_cleaned)) 

# Row-wise
summary((rowSums(is.na(data_cleaned))))

# Investigate missing drug test data
#missing_drug_tests <- data_cleaned %>% filter(is.na(DrugTests_THC_Positive) | is.na(DrugTests_Meth_Positive))
#colSums(is.na(missing_drug_tests))

# Investigate missing Jobs data 
#missing_jobs <- data_cleaned %>% filter(is.na(Jobs_Per_Year))
#colSums(is.na(missing_jobs))

# For now just drop NAs
#data_cleaned <- data_cleaned %>%
#  na.omit() # removes almost half of our observations but data set still very large (note that this removes all entries for females)
```

```{r}
### Resolve missing data 

# Categorical vars
data_cleaned <- data_cleaned %>%
  mutate(Gang_Affiliated = ifelse(Gender == "F", "false", Gang_Affiliated),
         Supervision_Risk_Score_First = ifelse(is.na(Supervision_Risk_Score_First), "missing",   Supervision_Risk_Score_First),
         Supervision_Level_First = ifelse(is.na(Supervision_Level_First), "missing", Supervision_Level_First),
         Prison_Offense = ifelse(is.na(Prison_Offense), "missing", Prison_Offense))

```


```{r}
# Remove 'DrugTest' vars (significant proportion is missing)
data_cleaned <- data_cleaned %>%
  dplyr::select(-c(DrugTests_Cocaine_Positive, DrugTests_Meth_Positive, DrugTests_Other_Positive,   Avg_Days_per_DrugTest,DrugTests_THC_Positive))
  
# Replace missing jobs data with values 0
data_cleaned <- data_cleaned %>%
  mutate(Percent_Days_Employed = ifelse(is.na(Percent_Days_Employed), 0, Percent_Days_Employed),
         Jobs_Per_Year = ifelse(is.na(Jobs_Per_Year), 0, Jobs_Per_Year))

colSums(is.na(data_cleaned)) 
```

```{r}
### Set up dependent var and covariate matrix
y <- data_cleaned %>%
  dplyr::select(Recidivism_Within_3years) %>%
  mutate(Recidivism_Within_3years = ifelse(Recidivism_Within_3years == "true", 1, 0)) %>%
  as.matrix()%>%
  as.integer()

# 8423 observations correspond to a reoffence within three years
#sum(y$Recidivism_Within_3years)/length(y)

### Covariate matrix - removed supervision_risk_score as this is what we're trying to predict
X <- data_cleaned %>%
  rename(Age = Age_at_Release, Residence = Residence_PUMA, Supervision_Level = Supervision_Level_First) %>%
  dplyr::select(-c(ID, Recidivism_Arrest_Year1, Recidivism_Arrest_Year2, Recidivism_Arrest_Year3, Training_Sample,Recidivism_Within_3years, Supervision_Risk_Score_First)) 

# dummy col 
#dummy_colnames <- X %>% select(-c(Avg_Days_per_DrugTest, DrugTests_THC_Positive,DrugTests_Cocaine_Positive, #DrugTests_Meth_Positive, DrugTests_Other_Positive, Percent_Days_Employed, Jobs_Per_Year)) %>%
#  names()

# Rename vars
colnames(X) <- gsub("Episodes_","",colnames(X))  

dummy_colnames <- X %>% select(-c(Percent_Days_Employed, Jobs_Per_Year)) %>%
  names()

X <- dummy_cols(X, select_columns = dummy_colnames, remove_first_dummy = TRUE, remove_selected_columns = TRUE)

X <- model.matrix(~., data = X)

```

## Models

### Regular logistic model
Useful resource: <https://rpubs.com/raoulbia/interpreting_glm_logistic_regression_output>

```{r}
glm.fit <- glm(y ~.,family=binomial(link='logit'), data = as.data.frame(X[,-1]))
#summary(glm.fit)
```

```{r}
## Store results
results <- glm.fit %>% 
  tidy() 

results <- results %>%
  mutate(exp_estimate = exp(estimate)) %>%
  select(term, exp_estimate)

results[,2:ncol(results)] <- round(results[,2:ncol(results)], 4) 

# Get CIs
mle_CI <- confint(glm.fit)

exp_mle_CIs <- exp(mle_CIs) %>%
  round(4)

results_table <-cbind(results, exp_mle_CIs)

## Make table for Latex
print(xtable(results, type = "latex"), include.rownames=FALSE)
```

```{r}
# Check in-sample fit
pred <- predict(glm.fit, newx = X[,-1])

MLE_insample <- assess.glmnet(pred, newy = y, family = "binomial")$auc
```

```{r}
# Pseudo R2
round(pR2(glm.fit),2)
```

```{r}
### Assess out-of-sample performance

#Implement 10-fold Cross validation
kfoldCV.mle <- function(y , x, K = 10, seed = 1) {
  ## Perform K-fold cross-validation for logistic regression
  ## Input
  ## - y: response
  ## - x: data.frame with predictors, intercept should not be present
  ## - K: number of folds in K-fold cross-validation
  ## - seed: random number generator seed (optional)
  ## Output
  ## - pred: cross-validated predictions for y
  ## - ssr: residual sum of squares, sum((y-pred)^2)
  if (!missing(seed)) set.seed(seed)
  subset <- rep(1:K,ceiling(nrow(x)/K))[1:nrow(x)]
  subset <- sample(subset,size=nrow(x),replace=FALSE)
  pred <- double(nrow(x))
  if (ncol(x)>0) {
    for (k in 1:K) {
      sel <- subset==k 
      fit <- glmnet(x=x[!sel,,drop=FALSE], y=y[!sel], family="binomial", lambda=0)  
      pred[sel] <- predict(fit, newx=x[sel,,drop=FALSE])
    }
  } else {
    for (k in 1:K) {
      sel <- subset==k
      pred[sel] <- mean(y[!sel],na.rm=TRUE)
    }
  }
  return(list(pred=pred))
}

cv.mle = kfoldCV.mle(y = y, x= as.matrix(X[,-1]), K = 10, seed = 1)

# 10-fold cross-validated AUC
cv.mle.perf <-assess.glmnet(cv.mle$pred, newy = y, family = "binomial")$auc
cv.mle.perf
```

```{r}
confusion.glmnet(cv.mle$pred, newy = y,family='binomial')
```

```{r}
plt<- plot(roc.glmnet(cv.mle$pred, newy = y,family='binomial'),type="s")+title(main = "MLE ROC") + text(0.8,0.1,paste("AUC=", round(cv.mle.perf$auc[1],5)))
```

### LASSO

```{r}
### LASSO Model
cv_lasso <- cv.glmnet(X[,-1], y, family="binomial", n_folds = 10, type.measure = 'auc')
plot(cv_lasso)
# In-sample AUC
paste("AUC: ", round(cv_lasso$cvm[cv_lasso$index[1]], 5))

#fit.lassoCV <-kfoldCV.lasso(y = y, x= as.matrix(X[,-1]),K=10,seed=1,criterion="cv")$pred

# Coefficients
lasso_estimate <- coef(cv_lasso, s=cv_lasso$lambda.min) 
 
```

```{r}
# Non-zero covariates
paste('Non-zero covariates:',cv_lasso$nzero[cv_lasso$index[1]])
paste('Variable count pushed to zero =',sum(coef(cv_lasso,s='lambda.min') ==0))
paste("lambda=", round(cv_lasso$lambda.min,6))
```

```{r}
plt<-plot(cv_lasso$glmnet.fit, xvar='lambda')
```

### LASSO BIC

```{r}
fit.lassobic= lasso.bic(y = y, x= as.matrix(X[,-1]),extended = FALSE)
fit.lassoBICcv <-kfoldCV.lasso(y = y, x= as.matrix(X[,-1]), K = 10, seed = 1,criterion="bic")


```

```{r}
confusion.glmnet(fit.lassoBICcv$pred, newx = x[,-1], newy = y,family='binomial')
lassoBIC.perf<-assess.glmnet(fit.lassoBICcv$pred,newy=y,family='binomial')
cat('AUC Score = ',lassoBIC.perf$auc)

```

```{r}
lassoBIC.auc <- lassoBIC.perf$auc
lassoBIC.mise <- lassoBIC.perf$class
plt<-plot(roc.glmnet(fit.lassoBICcv$pred, newy = y,family='binomial'),type="s") + 
  title(main = "BIC ROC")+ text(0.8,0.2,paste("AUC=", round(lassoBIC.perf$auc,5)))+text(0.8,0.1,paste("lambda=", round(fit.lassobic$lambda.opt,5)))
```

```{r}
paste('Variable count pushed to 0 by BIC :',length(which(fit.lassobic$coef==0)))

```

```{r}
plot(coef(glm.fit),xlab='Index', ylab= "Beta for variable i",main='Coefficients',col = "red",pch=4)
points(coef(cv_lasso,s='lambda.min'),col = "blue",pch=2) 
points(fit.lassobic$coef,pch=1,col = 'darkorange',)
legend(x = "bottomright", legend = c('MLE','LASSO','BIC'),col=c("red", "blue",'darkorange'), pch=c(4,2,1),cex = 1)
```

```{r}
plot(roc.glmnet(cv.mle$pred, newy = y,family='binomial'),type="s",col='red') 
#lines(roc.glmnet(fit.lassoCV, newy = y,family='binomial',s=cv_lasso$lambda.min),col = 'blue')
lines(roc.glmnet(fit.lassoBICcv$pred, newy = y,family='binomial',s=fit.cvlasso$lambda.min),col='darkorange')
legend(x = "bottomleft", legend = c('MLE','BIC'),col=c("red",'darkorange'),pch = c(20,20),cex = 1)
title(main = 'ROC curve for different models')
```

### Adaptive LASSO
<https://ricardocarvalho.ca/post/lasso/>
<https://rpubs.com/kaz_yos/alasso>
```{r}
# Extract coefficients from LASSO regression
lasso_coef <- 1/abs(matrix(coef(cv_lasso, s=cv_lasso$lambda.min)))
lasso_coef[lasso_coef== Inf] <- 999999999

# Run Adaptive LASSO
adapt_lasso <- cv.glmnet(X[,-1], y, family='binomial', alpha=1, type.measure='auc', penalty.factor=lasso_coef[2:length(lasso_coef)])

# Number of non-zero covariates
paste('Non-zero covariates:',adapt_lasso$nzero[adapt_lasso$index[1]])

# In-sample AUC
paste("AUC: ", round(adapt_lasso$cvm[adapt_lasso$index[1]], 5))

# Cross-validation
cv_adapt_lasso <- kfoldCV.lasso(y = y, x= as.matrix(X[,-1]),K=10,seed=1,criterion="adaptive_cv")

# Cross-validated AUC
cv.adapt_lasso.perf <-assess.glmnet(cv_adapt_lasso$pred, newy = y, family = "binomial")$auc
```


### Hierarchical Models?

<https://stats.oarc.ucla.edu/r/dae/mixed-effects-logistic-regression/>

```{r}

```

```{r}
### Cross-validation for LASSO

kfoldCV.lasso <- function(y,x,K=10,seed = 1,criterion='cv') {
## Perform K-fold cross-validation for LASSO regression estimate (lambda set either via cross-val or BIC or EBIC)
## Input
## - y: response
## - x: data.frame with predictors, intercept should not be present
## - K: number of folds in K-fold cross-validation
## - seed: random number generator seed (optional)
## - criterion: the criterion to select the penalization parameter, either cross-val or BIC or EBIC
## Output
## - pred: cross-validated predictions for y
## - ssr: residual sum of squares, sum((y-pred)^2)
  require(glmnet)
  if (!missing(seed)) set.seed(seed)
  subset <- rep(1:K,ceiling(nrow(x)/K))[1:nrow(x)]
  subset <- sample(subset,size=nrow(x),replace=FALSE)
  pred <- double(nrow(x))
  cat("Starting cross-validation")
  if (ncol(x)>0) {  #if there are some covariates
    for (k in 1:K) {
        sel <- subset==k
        if (criterion=='cv') {
            fit <- cv.glmnet(x=x[!sel,,drop=FALSE], y=y[!sel], family = "binomial", alpha = 1,                           nfolds=10, type.measure = 'auc')
            b= as.vector(coef(fit,s='lambda.min'))
            pred[sel] <- b[1] + x[sel,,drop=FALSE] %*% as.matrix(b[-1])
        } else if (criterion=='bic'){
            fit <- lasso.bic(y=y[!sel],x=x[!sel,,drop=FALSE])
            pred[sel] <- fit$coef[1] + x[sel,,drop=FALSE] %*% matrix(fit$coef[-1],ncol=1)
        } else if (criterion=='ebic'){
            fit <- lasso.bic(y=y[!sel],x=x[!sel,,drop=FALSE],extended = TRUE)
            pred[sel] <- fit$coef[1] + x[sel,,drop=FALSE] %*% matrix(fit$coef[-1],ncol=1) 
        } else { stop("method.lambda not implemented") }
        cat(".")
    }
  } else { #if there are no covariates, just use the intercept
    for (k in 1:K) {
      sel <- subset==k
      pred[sel] <- mean(y[!sel],na.rm=TRUE)
    }
  }
  cat("\n")
  return(list(pred=pred,ssr=sum((pred-y)^2,na.rm=TRUE)))
}

cv_cv_lasso <- kfoldCV.lasso(y, X[,-1], criterion = "cv")

outsample_lasso <- assess.glmnet(cv_cv_lasso$pred, newy = y, family = "binomial")$auc
```

```{r}
### Obtain CIs & P-values for LASSO

# Helper function
lassopost <- function(y,x, method.lambda, verbose = FALSE) {
#Run LASSO + post-selection inference on selected coefficients. lambda set via 10-fold cross-validation
#Input
# - y: response variable
# - x: design matrix
#
# Output: matrix with parameter estimates, 95% CIs and P-values for the variables selected by LASSO (lambda set via cross-validation), using the post-selection inference method of Lee et al (2016)
require(glmnet)
require(selectiveInference)
x= x[,apply(x,2,'sd') > 0] #remove intercept
xstd= scale(x); ystd= scale(y) #important!
if (is.null(colnames(x))) {
colnames(xstd)= paste('X',1:ncol(xstd),sep='')
} else {
colnames(xstd)= colnames(x)
}
#Estimate residual variance
sigmahat= estimateSigma(x=xstd, y=ystd, standardize=FALSE)$sigmahat
#Set lambda
if (method.lambda == 'cv') {
cvfit= cv.glmnet(x=xstd, y=ystd, nfolds=10,exact=TRUE)
lambda= cvfit$lambda.min
} else if (method.lambda == 'bic') {
lambda= lasso.bic(y=ystd, x=xstd)$lambda.opt
} else { stop("method.lambda not implemented") }
#LASSO estimate for selected lambda 
gfit= glmnet(x=xstd, y=ystd, standardize=FALSE, lambda=lambda,exact=TRUE,thresh=1e-25)
b= coef(gfit,exact=TRUE)[-1]
#Post-selection inference
lcv= fixedLassoInf(x=xstd,y=ystd,beta=b,lambda=lambda*nrow(x),sigma=sigmahat,verbose=verbose)
sel.lasso= (b!=0)
ci.lassopost= matrix(0,nrow=length(b),ncol=4)
colnames(ci.lassopost)= c('estimate','ci.low','ci.up','pvalue'); rownames(ci.lassopost)= colnames(xstd)
ci.lassopost[b != 0,]= cbind(lcv$coef0, lcv$ci, lcv$pv)
ci.lassopost[b == 0,4]= NA
return(ci.lassopost)
}

ci.lassopost= lassopost(y, X, method.lambda='cv')

```

### Assemble regression results

```{r}
### Accuracy results
accuracy_results <- data.frame(Model = c("Standard Logisitic", "LASSO", "Adaptive LASSO"), 
           "Covariates included" = c(134, cv_lasso$nzero[cv_lasso$index[1]]), adapt_lasso$nzero[adapt_lasso$index[1]],    
           "In-sample AU" = c(round(MLE_insample,5), round(cv_lasso$cvm[cv_lasso$index[1]], 5), round(adapt_lasso$cvm[adapt_lasso$index[1]], 5)),
           "Crossvalidated AUC" = c(round(cv.mle.perf,5),  round(outsample_lasso,5), round(cv.adapt_lasso.perf,5)))

## Make table for Latex
print(xtable(accuracy_results, type = "latex"))

```

### Attempt Clustering
See: https://towardsdatascience.com/clustering-datasets-having-both-numerical-and-categorical-variables-ed91cdca0677
```{r}
### Attempt clustering of mixed variable types using Gower distance metric
categorical_colnames <- X %>% dplyr::select(-c(Percent_Days_Employed, Jobs_Per_Year)) %>%
  names()

# categorical vars need to be factors
X_clustering <- X %>%
  mutate_at(categorical_colnames, as.factor) 

# could only handle
gower_df <- daisy(X_clustering[1:20000,], metric = "gower")

summary(gower_df)
```

```{r}
### Choose optimal number of clusters using the 'Silhouette width'
silhouette <- c()
silhouette = c(silhouette, NA)
for(i in 1:5){
  pam_clusters = pam(as.matrix(gower_df),
                 diss = TRUE,
                 k = i)
  silhouette = c(silhouette ,pam_clusters$silinfo$avg.width)
}
plot(1:10, silhouette,
     xlab = "Clusters",
     ylab = "Silhouette Width")
lines(1:10, silhouette)
```
